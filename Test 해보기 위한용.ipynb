{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import xgboost\n",
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from preprocessing import Nielsen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 데이터 있는곳 위치\n",
    "load_path = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd()))),'nielsen_pickle_data(180110)')\n",
    "final_file_name = 'final_data_171215'\n",
    "\n",
    "# seed\n",
    "split_seed = 0\n",
    "state_seed = 0\n",
    "\n",
    "devide_points_list = [5.986000e+03, 1.439980e+04, 4.039190e+04]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(datatable, split_point_list):\n",
    "    return np.split(datatable.sample(frac = 1, random_state = split_seed), split_point_list)\n",
    "\n",
    "def print_duration(start):\n",
    "    print('{}s 걸림'.format(time.time() - start))\n",
    "\n",
    "def make_result_table(datatable, model):\n",
    "    sub_table = datatable.copy()[['일자','프로그램명','프로그램편성시작시간','목표']]\n",
    "    sub_table['예측']=model.predict(datatable.values[:,4:])\n",
    "    return sub_table\n",
    "\n",
    "def make_no_channel_data(data):\n",
    "    no_channel_col_list = list()\n",
    "    for col in data.columns:\n",
    "        if '채널' not in col:\n",
    "            no_channel_col_list.append(col)\n",
    "    data_no_channel = data[no_channel_col_list]\n",
    "    li = list()\n",
    "    for col in data_no_channel.columns:\n",
    "        if '2_' not in col:\n",
    "            if '가중치' not in col:\n",
    "                li.append(col)\n",
    "    data_no_channel = data_no_channel[li]\n",
    "    return data_no_channel\n",
    "\n",
    "def result_table_error_rate(data, rate = 0.2):\n",
    "    data['차이정도'] = data.apply(lambda x: np.abs((x['목표'] - x['예측']) / x['목표']), axis=1)\n",
    "    return len(data[data['차이정도'] < rate]) / len(data)\n",
    "\n",
    "def change_list_to_tuple(li):\n",
    "    if li[0]!=0:\n",
    "        li.insert(0, 0)\n",
    "    li.append(100000000000000)\n",
    "    tmp = list()\n",
    "    for i in range(len(li)-1):\n",
    "        tmp.append((li[i], li[i+1]))\n",
    "    return tmp\n",
    "\n",
    "def change2Class(x, tup):\n",
    "    result = int()\n",
    "    for idx, (a,b) in enumerate(tup):\n",
    "        if a < x <= b:\n",
    "            result = idx\n",
    "    return result\n",
    "\n",
    "\n",
    "def train_regression_model(string, model, dictionary):\n",
    "    print('{}(regression)'.format(string))\n",
    "    model.fit(dictionary['train'][0], dictionary['train'][1])\n",
    "    for key in dictionary.keys():\n",
    "        print(\"{}      :  {:,}\".format(key, mean_squared_error(dictionary[key][1], model.predict(dictionary[key][0]))))\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_classification_model(string, model, dictionary):\n",
    "    print('{}(classification)'.format(string))\n",
    "    model.fit(dictionary['train'][0], dictionary['train'][1])\n",
    "    for key in dictionary.keys():\n",
    "        print(\"{}      :  {:,}\".format(key, accuracy_score(dictionary[key][1], model.predict(dictionary[key][0]))))\n",
    "\n",
    "    return model\n",
    "\n",
    "def regression(data, cut_rate=0.2):\n",
    "    no_channel_data, d3_train, d3_validate, d3_test, d3_dict = data_preprocessing(data, bool_classification = False)\n",
    "\n",
    "    ## RandomForest\n",
    "    # regr = RandomForestRegressor(n_estimators=20, random_state=state_seed)\n",
    "    # regr = train_regression_model('RandomForest', regr, dict)\n",
    "\n",
    "    # xgboost\n",
    "    xgb = xgboost.XGBRegressor(max_depth=10, random_state=0)\n",
    "    xgb_result = train_regression_model('XgBoost', xgb, d3_dict)\n",
    "\n",
    "    # result table\n",
    "    result_table = make_result_table(d3_test, xgb)\n",
    "\n",
    "    print('\\n목표값과 +- rate가 {}인 경우, Accuracy: {}'.format(cut_rate, result_table_error_rate(result_table, cut_rate)))\n",
    "    return xgb_result, result_table\n",
    "\n",
    "\n",
    "def classification(data):\n",
    "    # 그냥 지상파인지 여부만 체크\n",
    "\n",
    "    no_channel_data, d3_train, d3_validate, d3_test, d3_dict = data_preprocessing(data, bool_classification = True)\n",
    "\n",
    "    # classification 인 경우,\n",
    "    ## RandomForest\n",
    "    # randomForest = RandomForestClassifier(n_estimators=10, random_state=0)\n",
    "    # randomForest_result = train_classification_model('RandomForest', randomForest, data_dictionary)\n",
    "    # randomForest_result.predict_proba(data_dictionary['test'][0])\n",
    "\n",
    "    ## AdaBoost\n",
    "    # adaboost = AdaBoostClassifier(n_estimators=20, random_state=0)\n",
    "    # adaboost_result = train_classification_model('Adaboost', adaboost, data_dictionary)\n",
    "    # adaboost_result.predict_proba(data_dictionary['test'][0])\n",
    "\n",
    "    ## XgBoost\n",
    "    xbg = xgboost.XGBClassifier(max_depth=10, random_state=0)\n",
    "    xbg_result = train_classification_model('XgBoost', xbg, d3_dict)\n",
    "    # xbg_result.predict_proba(data_dictionary['test'][0])\n",
    "\n",
    "    ##Voting 하는 경우,\n",
    "    # voting = VotingClassifier(estimators=[\n",
    "    #     ('random', randomForest)\n",
    "    #     , ('ada', adaboost)\n",
    "    #     , (' xgboost', xbg)\n",
    "    # ]\n",
    "    #     , voting='soft')\n",
    "    # voting_result = train_classification_model('Voting', voting, data_dictionary)\n",
    "    # voting_result.predict_proba(data_dictionary['test'][0])\n",
    "\n",
    "\n",
    "    return xbg_result\n",
    "\n",
    "def data_preprocessing(datatable, bool_classification=False):\n",
    "    data = datatable.copy()\n",
    "    data['지상파'] = data.apply(lambda x: 1 if x['채널_1'] + x['채널_2'] + x['채널_3'] + x['채널_4'] + x['채널_5'] == 1 else 0,\n",
    "                             axis=1)\n",
    "    # target 을 class 데이터로 바꿔줌\n",
    "    if bool_classification:\n",
    "        li = change_list_to_tuple(devide_points_list)\n",
    "        data['목표'] = data['목표'].apply(lambda x: change2Class(x, li))\n",
    "\n",
    "    no_channel_data = make_no_channel_data(data)\n",
    "\n",
    "    # Data\n",
    "    ## - train, validate, test 세개로 나눈 경우\n",
    "    d3_train, d3_validate, d3_test = split_dataset(no_channel_data,\n",
    "                                                   [int(.6 * len(no_channel_data)), int(.8 * len(no_channel_data))])\n",
    "\n",
    "    d3_train_x, d3_train_y = d3_train.iloc[:, 4:].values, d3_train.iloc[:, 3].values\n",
    "    d3_validate_x, d3_validate_y = d3_validate.iloc[:, 4:].values, d3_validate.iloc[:, 3].values\n",
    "    d3_test_x, d3_test_y = d3_test.iloc[:, 4:].values, d3_test.iloc[:, 3].values\n",
    "\n",
    "    d3_dict = dict(\n",
    "        {'train': (d3_train_x, d3_train_y), 'validate': (d3_validate_x, d3_validate_y), 'test': (d3_test_x, d3_test_y)})\n",
    "\n",
    "    return no_channel_data, d3_train, d3_validate, d3_test, d3_dict\n",
    "\n",
    "def change_features(prog_from, prog_to, data_no_channel):\n",
    "    prog_from_copy= prog_from.copy()\n",
    "    prog_to_copy= prog_to.copy()\n",
    "    change_col_list = list()\n",
    "    for idx, col in enumerate(data_no_channel.columns):\n",
    "        if ('가중치' in col) or ('성별' in col) or ('연령' in col):\n",
    "            change_col_list.append(idx)\n",
    "    for idx in change_col_list:\n",
    "        prog_to_copy[idx] = prog_from_copy[idx]\n",
    "    return prog_to_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. data 로드\n",
      "1. regression\n",
      "XgBoost(regression)\n",
      "train      :  342,423,665.41295725\n",
      "validate      :  1,567,003,610.9663174\n",
      "test      :  1,535,932,658.2591827\n",
      "\n",
      "목표값과 +- rate가 0.2인 경우, Accuracy: 0.2456987466662018\n",
      "///////////////////\n",
      "2. classification\n",
      "XgBoost(classification)\n",
      "train      :  0.716770965886311\n",
      "validate      :  0.5453135077657887\n",
      "test      :  0.5403803580455663\n"
     ]
    }
   ],
   "source": [
    "# data load\n",
    "print('0. data 로드')\n",
    "data = pd.read_csv(os.path.join(load_path, '{}.csv'.format(final_file_name)), engine='python', encoding='cp949')\n",
    "# XgBoost가 성능이 제일 잘 나와서 XgBoost만 사용\n",
    "print('1. regression')\n",
    "reg_result, reg_result_table = regression(data, 0.2)\n",
    "print('2. classification')\n",
    "cl_result = classification(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bool_classification = True\n",
    "#classification인 경우, True\n",
    "no_channel_data, train, validate, test, dictionary = data_preprocessing(data, bool_classification = bool_classification)\n",
    "if bool_classification:\n",
    "    model = cl_result\n",
    "else:\n",
    "    model = reg_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 개\n",
      "[20170408 '백종원의3대천왕' 71185 3]\n",
      "[3]\n",
      "[[  2.66055322e-05   2.61076857e-05   7.22554978e-05   9.99875069e-01]]\n"
     ]
    }
   ],
   "source": [
    "# 백종원 3대천왕\n",
    "sbs_a = no_channel_data[(no_channel_data['프로그램명']=='백종원의3대천왕')\n",
    "               &(no_channel_data['지상파']==1)\n",
    "               &(no_channel_data['일자']==20170408)].values\n",
    "print('{} 개'.format(len(sbs_a)))\n",
    "print(sbs_a[0][:4])\n",
    "print(model.predict(sbs_a[0][4:].reshape(1,-1)))\n",
    "if bool_classification:\n",
    "    print(model.predict_proba(sbs_a[0][4:].reshape(1,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 개\n",
      "[20170407 '미운우리새끼다시쓰는육아일기' 90081 1000196.0000000001]\n",
      "[ 930544.375]\n"
     ]
    }
   ],
   "source": [
    "# 미운우리새끼\n",
    "sbs_b = no_channel_data[(no_channel_data['프로그램명']=='미운우리새끼다시쓰는육아일기')\n",
    "               &(no_channel_data['지상파']==1)\n",
    "               &(no_channel_data['일자']==20170407)].values\n",
    "print('{} 개'.format(len(sbs_b)))\n",
    "print(sbs_b[0][:4])\n",
    "print(model.predict(sbs_b[0][4:].reshape(1, -1)))\n",
    "if bool_classification:\n",
    "    print(model.predict_proba(sbs_b[0][4:].reshape(1, -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 개\n",
      "[20170409 'K팝스타더라스트찬스' 83536 3]\n",
      "[3]\n",
      "[[  3.69283553e-05   3.30287294e-05   5.44007744e-05   9.99875665e-01]]\n"
     ]
    }
   ],
   "source": [
    "# K팝스타더라스트찬스\n",
    "sbs_c = no_channel_data[(no_channel_data['프로그램명']=='K팝스타더라스트찬스')\n",
    "               &(no_channel_data['지상파']==1)\n",
    "               &(no_channel_data['일자']==20170409)].values\n",
    "print('{} 개'.format(len(sbs_c)))\n",
    "print(sbs_c[0][:4])\n",
    "print(model.predict(sbs_c[0][4:].reshape(1, -1)))\n",
    "if bool_classification:\n",
    "    print(model.predict_proba(sbs_c[0][4:].reshape(1, -1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sbs_a(3대천왕) 를 sbs_b(미운우리새끼) 시간대로 옮긴 경우,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n",
      "[[  2.63467227e-05   3.14399949e-05   7.77135720e-05   9.99864459e-01]]\n"
     ]
    }
   ],
   "source": [
    "result_1 = change_features(sbs_a[0], sbs_b[0], cl_no_channel_data)\n",
    "print(model.predict(result_1[4:].reshape(1,-1)))\n",
    "if bool_classification:\n",
    "    print(model.predict_proba(result_1[4:].reshape(1,-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sbs_b(미운우리새끼) 를 sbs_c(K팝스타) 시간대로 옮긴 경우,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n",
      "[[  3.85473541e-05   2.86694940e-05   7.03256883e-05   9.99862432e-01]]\n"
     ]
    }
   ],
   "source": [
    "result_2 = change_features(sbs_b[0], sbs_c[0], cl_no_channel_data)\n",
    "print(model.predict(result_2[4:].reshape(1,-1)))\n",
    "if bool_classification:\n",
    "    print(model.predict_proba(result_2[4:].reshape(1,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
